{
  "age": {
    "precision": 0.6764705882352942,
    "recall": 0.92,
    "f1-score": 0.7796610169491526,
    "support": 25,
    "confused_with": {}
  },
  "diet": {
    "precision": 0.8979591836734694,
    "recall": 0.7213114754098361,
    "f1-score": 0.8,
    "support": 61,
    "confused_with": {
      "allergen": 1
    }
  },
  "height": {
    "precision": 1.0,
    "recall": 0.7419354838709677,
    "f1-score": 0.8518518518518519,
    "support": 31,
    "confused_with": {
      "age": 5,
      "activity_level": 2
    }
  },
  "activity_level": {
    "precision": 0.8888888888888888,
    "recall": 0.7619047619047619,
    "f1-score": 0.8205128205128205,
    "support": 21,
    "confused_with": {}
  },
  "gender": {
    "precision": 1.0,
    "recall": 0.9333333333333333,
    "f1-score": 0.9655172413793104,
    "support": 15,
    "confused_with": {}
  },
  "allergen": {
    "precision": 0.9714285714285714,
    "recall": 0.8095238095238095,
    "f1-score": 0.8831168831168832,
    "support": 42,
    "confused_with": {}
  },
  "weight": {
    "precision": 0.8260869565217391,
    "recall": 0.8260869565217391,
    "f1-score": 0.8260869565217391,
    "support": 23,
    "confused_with": {
      "age": 4
    }
  },
  "micro avg": {
    "precision": 0.8826530612244898,
    "recall": 0.7935779816513762,
    "f1-score": 0.8357487922705314,
    "support": 218
  },
  "macro avg": {
    "precision": 0.8944048841068518,
    "recall": 0.8162994029377783,
    "f1-score": 0.8466781100473939,
    "support": 218
  },
  "weighted avg": {
    "precision": 0.8997887228285809,
    "recall": 0.7935779816513762,
    "f1-score": 0.8371714209793769,
    "support": 218
  },
  "accuracy": 0.9757155247181266
}